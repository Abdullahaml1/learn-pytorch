{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3998151a-7271-4787-a88a-3464b84170e2",
   "metadata": {},
   "source": [
    "# Tensors [link](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a371aa-787f-4569-8e2e-62872e83c642",
   "metadata": {},
   "source": [
    "Tensors share the smae properties with numpy indexing, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab6a802-319e-4735-a662-504810f5a170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643df975-6dd1-4d24-ac0f-c249fcca5578",
   "metadata": {},
   "source": [
    "## Initializing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5bcde1-a498-496d-8fc1-f1cc0f069bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from data\n",
    "\n",
    "data = [[1, 2],\n",
    "        [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd09442b-088f-4a26-8aae-658dae02118c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from numpy \n",
    "np_array = np.array(data)\n",
    "x_p = torch.from_numpy(np_array)\n",
    "x_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107b0fa8-7131-4c51-bd9f-db8bdbd003b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.3806, 0.9027],\n",
      "        [0.1579, 0.3980]])\n"
     ]
    }
   ],
   "source": [
    "# From another tensor\n",
    "\n",
    "#returun a tensor with same proprties (i.e: shape, device, datatype, ...) of the input tensor\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d9ad6c-b45d-4878-9dfe-40e0bfb14842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1050, 0.2412, 0.7552],\n",
      "        [0.9406, 0.6116, 0.0211]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# giving the imput dimetion\n",
    "shape = (2, 3,)\n",
    "\n",
    "rand_tensor = torch.rand(shape)\n",
    "print(rand_tensor)\n",
    "\n",
    "ones_tensor = torch.ones(shape)\n",
    "print(ones_tensor)\n",
    "\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b930564-eee5-4c1f-83be-486793fbab37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# some properties of tensor\n",
    "\n",
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33479180-82ad-461e-9b70-dd36c9c554a2",
   "metadata": {},
   "source": [
    "## Operation on Tesors [link](https://pytorch.org/docs/stable/torch.html)\n",
    "\n",
    "* pytorch by default uses cpu if you want to use gpu you must explicitly do that by method `.to` \n",
    "* if the tensor is large and was initialized on cpu moving the large tensors to gpu  could be an overhead over (cpu and memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6fd791b-586c-4195-8218-bd2a73cf6869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3c6072-562c-40fe-a0ec-8ca901acb540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "\n",
      "tensor([[0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1.]], device='cuda:0') \n",
      " tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "\n",
      "tensor([[1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.]]) \n",
      " tensor([0., 0., 0., 0.])\n",
      "\n",
      "tensor([[[1., 1., 1., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 0.]]]) \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4, device=device)\n",
    "# tensor.to(device)\n",
    "tensor = torch.ones(4, 4, device=device)\n",
    "\n",
    "\n",
    "#firist raw\n",
    "print(tensor[0])\n",
    "\n",
    "#first column\n",
    "tensor[:, 0] = 0\n",
    "print(f'\\n{tensor} \\n {tensor[:, 0]}')\n",
    "tensor = torch.ones(4, 4)\n",
    "\n",
    "#last column\n",
    "tensor[:, -1] = 0\n",
    "print(f'\\n{tensor} \\n {tensor[:, -1]}')\n",
    "tensor = torch.ones(4, 4)\n",
    "\n",
    "\n",
    "#last column of 3D tensor ->>> three dots '...' means rest of dimetionis\n",
    "tensor = torch.ones(2, 3, 4)\n",
    "tensor[..., -1] = 0\n",
    "print(f'\\n{tensor} \\n {tensor[..., -1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f373348-5a69-4598-af3c-25933899e5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatination also stacking see: https://pytorch.org/docs/stable/generated/torch.stack.html\n",
    "tensor = torch.ones(4, 4, device=device)\n",
    "out_tensor = torch.ones(4, 12, device=device)\n",
    "torch.cat([tensor, tensor, tensor], dim=-1, out = out_tensor)\n",
    "out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be377aa4-073a-4e4f-ace2-23757f8227dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]], device='cuda:0')\n",
      "\n",
      "matrix multplication \n",
      "y1=y2=y3 \n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]], device='cuda:0')\n",
      "\n",
      "elementwise multplication -> smae operation as matpul \n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4, device=device)\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "#matrix multplication\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = torch.matmul(tensor, tensor.T)\n",
    "torch.matmul(tensor, tensor.T, out=y2)\n",
    "y3= tensor.matmul(tensor.T)\n",
    "print(f'\\nmatrix multplication \\ny1=y2=y3 \\n{y1}')\n",
    "\n",
    "\n",
    "#elemntwise multplication -> smae operation as matpul\n",
    "z1 = tensor * tensor\n",
    "z2 = torch.mul(tensor, tensor)\n",
    "print(f'\\nelementwise multplication -> smae operation as matpul \\n{z1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c3462fe-851a-4d28-a9d7-db0e6715fe98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., device='cuda:0') 12.0\n"
     ]
    }
   ],
   "source": [
    "#converting tensor of shpe (1,) to python value\n",
    "agg = tensor.sum()\n",
    "print(agg, agg.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b57b03-27e2-4d7d-b8cc-1be2fb55e90d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6., 6.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [6., 6., 6., 6.]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace operatins ends with '_' means the ouput will be stored in the same varialble\n",
    "# CUATION: uing inplae operatoins will omit gradient while backprobagation\n",
    "\n",
    "tensor = torch.ones(4, 4, device=device)\n",
    "y = tensor.add(5) # normal\n",
    "\n",
    "tensor.add_(5) # inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37956751-b030-44ea-879c-ac48b32c1606",
   "metadata": {},
   "source": [
    "# Bridging with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca7e81c-bc8e-42c9-afa8-82f99b67fcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "[1. 1. 1. 1.]\n",
      "\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "\n",
      "[[5. 5.]\n",
      " [5. 5.]]\n",
      "tensor([[5., 5.],\n",
      "        [5., 5.]], dtype=torch.float64)\n",
      "\n",
      "[[9. 9.]\n",
      " [9. 9.]]\n",
      "tensor([[39., 39.],\n",
      "        [39., 39.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# converting tensor to numpy\n",
    "tensor = torch.ones(4, device='cpu')\n",
    "np_tensor = tensor.numpy()\n",
    "print(f'{tensor}\\n{np_tensor}')\n",
    "\n",
    "\n",
    "\n",
    "#numpy to tensor\n",
    "np_data = np.ones((2, 2))\n",
    "tensor = torch.from_numpy(np_data)\n",
    "print(f'\\n{np_data}\\n{tensor}')\n",
    "\n",
    "\n",
    "#change in numpy refleact tensor\n",
    "np.add(np_data, 4, out=np_data)\n",
    "print(f'\\n{np_data}\\n{tensor}')\n",
    "\n",
    "#change in tensor refleact numpy\n",
    "torch.add(tensor, 4, out=tensor)\n",
    "tensor = tensor.add(30) # this will create new varialbe called tensor (it shared no data with the previous tensor)\n",
    "print(f'\\n{np_data}\\n{tensor}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

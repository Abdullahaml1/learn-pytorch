{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db899271-3a04-42bb-bfbb-97fb94ecac54",
   "metadata": {},
   "source": [
    "# Pytorch Engite Metrics [link](https://pytorch.org/ignite/metrics.html#attach-engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b26aa3c-1024-48ea-acb8-e3625ac81ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7329d512-4203-4b33-a14c-3b49c56e9ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "input_dim = 5\n",
    "num_classes = 2\n",
    "data_dim = 10\n",
    "data = torch.randn(data_dim, input_dim), torch.randint(0, num_classes, (data_dim,))\n",
    "\n",
    "model = Classifier(input_dim, num_classes)\n",
    "model.to(device)\n",
    "data[0].to(device)\n",
    "data[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48958580-32cd-4c7a-9949-a0483be5e321",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  tensor([0.8333, 0.7500], device='cuda:0', dtype=torch.float64)\n",
      "Precision:  tensor([0.8333, 0.7500], device='cuda:0', dtype=torch.float64)\n",
      "Precision:  tensor([0.8333, 0.7500], device='cuda:0', dtype=torch.float64)\n",
      "Precision:  tensor([0.8333, 0.7500], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import Precision\n",
    "\n",
    "# Define the metric\n",
    "precision = Precision(average=None, device=device)   # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Start accumulation:\n",
    "# for x, y in data:\n",
    "x = data[0].to(device)\n",
    "y = data[1].to(device)\n",
    "y_pred = model(x)\n",
    "precision.update((y_pred, y))  # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Compute the result\n",
    "print(\"Precision: \", precision.compute())# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Reset metric\n",
    "precision.reset() \n",
    "\n",
    "# Start new accumulation:\n",
    "# for x, y in data:\n",
    "y_pred = model(x)\n",
    "precision.update((y_pred, y)) \n",
    "\n",
    "# Compute new result\n",
    "print(\"Precision: \", precision.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdee3918-7be0-4150-a76a-74e69ebad537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:  tensor([0.4000, 0.4000], device='cuda:0', dtype=torch.float64)\n",
      "recall:  tensor([0.4000, 0.4000], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import  Recall\n",
    "\n",
    "def to_li\n",
    "\n",
    "# Define the metric\n",
    "recall = Recall(average=None, device = device)\n",
    "\n",
    "# Start accumulation:\n",
    "# for x, y in data:\n",
    "x = data[0].to(device)\n",
    "y = data[1].to(device)\n",
    "y_pred = model(x)\n",
    "recall.update((y_pred, y))\n",
    "\n",
    "# Compute the result\n",
    "print(\"recall: \", recall.compute())\n",
    "\n",
    "# Reset metric\n",
    "recall.reset()\n",
    "\n",
    "# Start new accumulation:\n",
    "# for x, y in data:\n",
    "y_pred = model(x)\n",
    "recall.update((y_pred, y))\n",
    "\n",
    "# Compute new result\n",
    "print(\"recall: \", recall.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4970b0-f845-4fa6-84a0-6ce425660e95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7209, 0.6030, 0.4973, 0.4262, 0.5408, 0.4756, 0.5571, 0.5731, 0.4637,\n",
       "        0.7081], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.sigmoid(model(x))\n",
    "z[:,0].reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "265e2688-084a-47d8-b571-86428ef73336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (10, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m roc_auc\u001b[38;5;241m.\u001b[39mupdate((y_pred, y))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Compute the result\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mroc_auc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Reset metric\u001b[39;00m\n\u001b[1;32m     30\u001b[0m roc_auc\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ignite/metrics/epoch_metric.py:156\u001b[0m, in \u001b[0;36mEpochMetric.compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idist\u001b[38;5;241m.\u001b[39mget_rank() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Run compute_fn on zero rank only\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_prediction_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_target_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ws \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# broadcast result to all processes\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mfloat\u001b[39m, idist\u001b[38;5;241m.\u001b[39mbroadcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result, src\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ignite/contrib/metrics/roc_auc.py:15\u001b[0m, in \u001b[0;36mroc_auc_compute_fn\u001b[0;34m(y_preds, y_targets)\u001b[0m\n\u001b[1;32m     13\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_targets\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:626\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    624\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    625\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    635\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    636\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    640\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:386\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m     )\n\u001b[0;32m--> 386\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1094\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    993\u001b[0m     {\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m ):\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1094\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:807\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    805\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    806\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m--> 807\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m assert_all_finite(y_true)\n\u001b[1;32m    809\u001b[0m assert_all_finite(y_score)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1245\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1234\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1235\u001b[0m             (\n\u001b[1;32m   1236\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1242\u001b[0m         )\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1247\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (10, 2) instead."
     ]
    }
   ],
   "source": [
    "from ignite.contrib.metrics import ROC_AUC\n",
    "# Define the metric\n",
    "\"\"\"\n",
    "ROC_AUC expects y to be comprised of 0’s and 1’s. y_pred must either\n",
    "be probability estimates or confidence values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sigmoid_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = torch.sigmoid(y_pred)[:,0].reshape([-1])\n",
    "    y = y.reshape([-1])\n",
    "    print(y.shape, y_pred.shape)\n",
    "    return y_pred, y\n",
    "\n",
    "roc_auc = ROC_AUC(output_transform=sigmoid_output_transform, device = device)\n",
    "\n",
    "# Start accumulation:\n",
    "# for x, y in data:\n",
    "x = data[0].to(device)\n",
    "y = data[1].to(device)\n",
    "y_pred = model(x)\n",
    "# z, y = sigmoid_output_transform((y_pred, y))\n",
    "roc_auc.update((y_pred, y))\n",
    "\n",
    "# Compute the result\n",
    "print(\"roc_auc: \", roc_auc.compute())\n",
    "\n",
    "# Reset metric\n",
    "roc_auc.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffdba81e-0d89-452b-b068-6992832ccbcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.9677]), tensor([1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def sigmoid_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = torch.sigmoid(y_pred)[:,0].reshape([-1])\n",
    "    print(y_pred.shape)\n",
    "    return y_pred, y\n",
    "x = (torch.tensor([[3.4, -2.1]]), torch.tensor([1]))\n",
    "sigmoid_output_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "790595c8-e93f-45db-ab17-64c3d0f2c0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm:  tensor([[2, 3],\n",
      "        [3, 2]], device='cuda:0')\n",
      "cm:  tensor([[2, 3],\n",
      "        [3, 2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import Loss\n",
    "\n",
    "# Define the metric\n",
    "cm = ConfusionMatrix(num_classes=num_classes, device=device)   # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Start accumulation:\n",
    "# for x, y in data:\n",
    "x = data[0].to(device)\n",
    "y = data[1].to(device)\n",
    "y_pred = model(x)\n",
    "cm.update((y_pred, y))  # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Compute the result\n",
    "print(\"cm: \", cm.compute())\n",
    "\n",
    "# Reset metric\n",
    "cm.reset() # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Start new accumulation:\n",
    "# for x, y in data:\n",
    "y_pred = model(x)\n",
    "cm.update((y_pred, y)) \n",
    "\n",
    "# Compute new result\n",
    "print(\"cm: \", cm.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9429ce-a44f-4662-9893-e50d9e182dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric loss -0.3499999940395355\n",
      "normal loss tensor(-0.3500)\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import Loss\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "metric = Loss(criterion)\n",
    "y_pred = torch.tensor([[0.1, 0.4, 0.5], [0.1, 0.7, 0.2]])\n",
    "y_true = torch.tensor([2, 2]).long()\n",
    "\n",
    "metric.reset()\n",
    "metric.update((y_pred, y_true))\n",
    "print('metric loss', metric.compute())\n",
    "print('normal loss', criterion(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f40d96-c760-4712-8f9a-d78e75590fe9",
   "metadata": {},
   "source": [
    "# Custom Roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92ba8159-8e61-4ea1-97b8-2754c7f426bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, cast, Tuple, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from ignite import distributed as idist\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics import EpochMetric\n",
    "\n",
    "\n",
    "def roc_auc_compute_fn(y_preds: torch.Tensor, y_targets: torch.Tensor) -> float:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    y_true = y_targets.cpu().numpy()\n",
    "    y_pred = y_preds.cpu().numpy()\n",
    "    return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "class Custom_ROC_AUC(EpochMetric):\n",
    "    \"\"\"Computes Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    accumulating predictions and the ground-truth during an epoch and applying\n",
    "    `sklearn.metrics.roc_auc_score <https://scikit-learn.org/stable/modules/generated/\n",
    "    sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score>`_ .\n",
    "\n",
    "    Args:\n",
    "        output_transform: a callable that is used to transform the\n",
    "            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n",
    "            you want to compute the metric with respect to one of the outputs.\n",
    "        check_compute_fn: Default False. If True, `roc_curve\n",
    "            <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#\n",
    "            sklearn.metrics.roc_auc_score>`_ is run on the first batch of data to ensure there are\n",
    "            no issues. User will be warned in case there are any issues computing the function.\n",
    "        device: optional device specification for internal storage.\n",
    "\n",
    "    Note:\n",
    "\n",
    "        ROC_AUC expects y to be comprised of 0's and 1's. y_pred must either be probability estimates or confidence\n",
    "        values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            def sigmoid_output_transform(output):\n",
    "                y_pred, y = output\n",
    "                y_pred = torch.sigmoid(y_pred)\n",
    "                return y_pred, y\n",
    "            avg_precision = ROC_AUC(sigmoid_output_transform)\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        .. include:: defaults.rst\n",
    "            :start-after: :orphan:\n",
    "\n",
    "        .. testcode::\n",
    "\n",
    "            roc_auc = ROC_AUC()\n",
    "            #The ``output_transform`` arg of the metric can be used to perform a sigmoid on the ``y_pred``.\n",
    "            roc_auc.attach(default_evaluator, 'roc_auc')\n",
    "            y_pred = torch.tensor([[0.0474], [0.5987], [0.7109], [0.9997]])\n",
    "            y_true = torch.tensor([[0], [0], [1], [0]])\n",
    "            state = default_evaluator.run([[y_pred, y_true]])\n",
    "            print(state.metrics['roc_auc'])\n",
    "\n",
    "        .. testoutput::\n",
    "\n",
    "            0.6666...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_transform: Callable = lambda x: x,\n",
    "        check_compute_fn: bool = False,\n",
    "        device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
    "    ):\n",
    "\n",
    "        try:\n",
    "            from sklearn.metrics import roc_auc_score  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ModuleNotFoundError(\"This contrib module requires scikit-learn to be installed.\")\n",
    "\n",
    "        super(Custom_ROC_AUC, self).__init__(\n",
    "            roc_auc_compute_fn, output_transform=output_transform, check_compute_fn=check_compute_fn, device=device\n",
    "        )\n",
    "        \n",
    "    def compute(self) -> float:\n",
    "        if len(self._predictions) < 1 or len(self._targets) < 1:\n",
    "            raise NotComputableError(\"EpochMetric must have at least one example before it can be computed.\")\n",
    "\n",
    "        if self._result is None:\n",
    "            _prediction_tensor = torch.cat(self._predictions, dim=0)\n",
    "            _target_tensor = torch.cat(self._targets, dim=0)\n",
    "\n",
    "            ws = idist.get_world_size()\n",
    "            if ws > 1:\n",
    "                # All gather across all processes\n",
    "                _prediction_tensor = cast(torch.Tensor, idist.all_gather(_prediction_tensor))\n",
    "                _target_tensor = cast(torch.Tensor, idist.all_gather(_target_tensor))\n",
    "\n",
    "            self._result = 0.0\n",
    "            if idist.get_rank() == 0:\n",
    "                # Run compute_fn on zero rank only\n",
    "                _out = self._output_transform((_prediction_tensor, _target_tensor))\n",
    "                self._result = self.compute_fn(_out[0], _out[1])\n",
    "\n",
    "            if ws > 1:\n",
    "                # broadcast result to all processes\n",
    "                self._result = cast(float, idist.broadcast(self._result, src=0))\n",
    "\n",
    "        return self._result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2830d3e0-acdd-4663-b468-24525d17b7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10]) torch.Size([10])\n",
      "roc_auc:  0.5\n"
     ]
    }
   ],
   "source": [
    "def sigmoid_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = torch.sigmoid(y_pred)[:,0].reshape([-1])\n",
    "    y = y.reshape([-1])\n",
    "    print(y.shape, y_pred.shape)\n",
    "    return y_pred, y\n",
    "\n",
    "roc_auc = Custom_ROC_AUC(output_transform=sigmoid_output_transform, device = device)\n",
    "\n",
    "# Start accumulation:\n",
    "# for x, y in data:\n",
    "x = data[0].to(device)\n",
    "y = data[1].to(device)\n",
    "y_pred = model(x)\n",
    "# z, y = sigmoid_output_transform((y_pred, y))\n",
    "roc_auc.update((y_pred, y))\n",
    "\n",
    "# Compute the result\n",
    "print(\"roc_auc: \", roc_auc.compute())\n",
    "\n",
    "# Reset metric\n",
    "roc_auc.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eadd3a-22a8-4eb9-94c6-bf9025154598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
